# Awesome_alternative_llms[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
open source ChatGPT and GPT4 alternatives for LLMs

 
## multi lang models
- [FastChat](https://github.com/lm-sys/FastChat)

- [Llama-X](https://github.com/AetherCortex/Llama-X)

## Chinese models
* [Chinese luotuo](https://github.com/LC1332/Chinese-alpaca-lora)

* [Chinese BELLE](https://github.com/LianjiaTech/BELLE)
 
### glm 6b
* [glm6b-ptuning](https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md)

* [glm6b-c++ mnn onnx](https://github.com/wangzhaode/ChatGLM-MNN)

#### lm6b-finetune-lora
* [ChatGLM-finetune-LoRA](https://github.com/lich99/ChatGLM-finetune-LoRA)

## multi-modal 
* [visual-openllm] (https://github.com/visual-openllm/visual-openllm)


## tools
* [langchain](https://github.com/hwchase17/langchain)

* [dataset-zbench](https://github.com/zhenbench/z-bench)


## finetune blog
* [fine-tune-alpaca-with-lora](https://replicate.com/blog/fine-tune-alpaca-with-lora?continueFlag=4ecae39885197a5c008faabbefb5c824)
* [hugging face official blog in chinese:在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs ](https://zhuanlan.zhihu.com/p/616346543?utm_medium=social&utm_oi=762255747382796288&utm_psn=1622284420437450752&utm_source=wechat_session&utm_id=0)
* [hugging face official blog :Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU ](https://huggingface.co/blog/trl-peft)

## others
- 常见的内存泄漏检查方法:

- 内存分析工具:Eclipse Memory Analyzer、VisualVM

